from __future__ import print_function
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.utils import np_utils
from keras.models import load_model
from keras.optimizers import SGD
from tools.DL_models import *


batch_size = 32
nb_classes = 2
nb_epoch = 100
data_augmentation = True
_load_model = False
_save_model = False

# input image dimensions
img_rows, img_cols = 32, 32
# Images are RGB.
img_channels = 3



model = Sequential()

model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=(img_rows,img_cols,img_channels)))
model.add(Activation('relu'))
model.add(Convolution2D(32, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Convolution2D(64, 3, 3, border_mode='same'))
model.add(Activation('relu'))
model.add(Convolution2D(64, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(nb_classes))
model.add(Activation('softmax'))

# let's train the model using SGD + momentum (how original).
sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

# else:
#     model = load_model('/home/eze/python_ws/models/model_cifar10_200e.h5')

#    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
#    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

# This will do preprocessing and realtime data augmentation:
train_datagen = ImageDataGenerator(
    rescale=1./255,
    featurewise_center=False,  # set input mean to 0 over the dataset
    samplewise_center=False,  # set each sample mean to 0
    featurewise_std_normalization=False,  # divide inputs by std of the dataset
    samplewise_std_normalization=False,  # divide each input by its std
    zca_whitening=False,  # apply ZCA whitening
    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
    horizontal_flip=True,  # randomly flip images
    vertical_flip=False)  # randomly flip images

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    '/home/luce_vayrac/kinect_datasets/DL_Ready/rollable_data_2/train',
    target_size=(32,32),
    batch_size=batch_size)
validation_generator = test_datagen.flow_from_directory(
    '/home/luce_vayrac/kinect_datasets/DL_Ready/rollable_data_2/validation',
    target_size=(32,32),
    batch_size=batch_size)
# Fit the model on the batches generated by datagen.flow().
model.fit_generator(generator=train_generator,
    samples_per_epoch=1006,
    nb_epoch=nb_epoch,
    verbose=1,
    validation_data=validation_generator,
    nb_val_samples=399
    # validation_steps=800,
    # class_weight=None, max_q_size=10, workers=1, pickle_safe=False, initial_epoch=0
    )

    # # save model
    # if _save_model:
    #     print("Saving model after " + str(i * 50) + " epochs")
    #     # model.save("" + str(i*50) + "e.h5")

    # i += 1
